---
title: "WolfSheep_07_Training_RandomForest"
author: "Femke Keij S2647168"
date: "2023-07-13"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
Clear working directory & set random seed:
```{r}
rm(list = ls(all = TRUE))

set.seed(42)
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for ggplot
library(directlabels)
library(patchwork)
library(ggbeeswarm)

# for creating the cross-validation folds
library(caret)

# for random forest
library(MultivariateRandomForest)
```

Read in the data:
```{r}
# training data
ws_train <- read_csv('data/processed/wolfsheep_timesteps_training.csv')
```

# Fitting with cross-validation
Function to compute errors for continuous parameters:
```{r}
ComputeErrorsContinuous <- function(predicted, true,
                                    mean_training, variable,
                                    fold){
  # predicted: predicted values
  # true: true values
  # mean_training: mean of values in training data set
  # variable & fold: labels to pass onto output
  
  N <- length(true)
  
  perc_correct <- sum(predicted == true) / N
  perc_correct_cat <- sum(predicted >= true - 0.1 * true &
                            predicted <= true + 0.1 * true)
  RMSE <- sqrt(sum((predicted - true)^2)) / N
  NRMSE <- (sqrt(sum((predicted - true)^2)) / N) / sd(true)
  point_pred <- 1 - sum(sqrt((predicted - true)^2)) /
                    sum(sqrt((true - mean_training)^2))
  
  return(tibble(fold = fold,
                variable = variable,
                perc_correct = perc_correct,
                perc_correct_cat = perc_correct_cat,
                RMSE = RMSE,
                NRMSE = NRMSE,
                point_pred = point_pred))
}
```

Function to cross-validate multivariate random forest:
```{r}
WolfSheepRandomForest <- function(data,
                                  sampling_method,
                                  timesteps,
                                  noise){
  # data: complete training data
  # sampling_method: method used to create that data
  # timesteps: which timesteps are included in the data
  # noise: whether or not noise was added to the data
  
  # create the folds
  flds <- createFolds(1:nrow(data),
                      k = 5, list = TRUE, returnTrain = FALSE)

  # to store the results
  results_df <- tibble(fold = numeric(),
                       variable = character(),
                       perc_correct = numeric(),
                       perc_correct_cat = numeric(),
                       RMSE = numeric(),
                       NRMSE = numeric(),
                       point_pred = numeric())

  # for each cross-validation fold
  for(i in 1:5){
    # remove the test fold to create the training data
    dat <- data %>%
      filter(!combination_number %in% unlist(flds[i])) %>%
      select(- combination_number)
  
    # obtain the test fold
    dat_test <- data %>%
      filter(combination_number %in% unlist(flds[i])) %>%
      select(- combination_number)
    
    # set up the output training data
    Y <- dat %>%
      select(c(initial_number_sheep, initial_number_wolves,
                 sheep_gain_from_food, wolves_gain_from_food,
                 sheep_reproduce, wolves_reproduce,
                 grass_regrowth)) %>%
      as.matrix()
    # set up the input parameter data
    X <- dat %>%
      select(- c(initial_number_sheep, initial_number_wolves,
                 sheep_gain_from_food, wolves_gain_from_food,
                 sheep_reproduce, wolves_reproduce,
                 grass_regrowth)) %>%
      as.matrix()
    # set up test data
    testX <- dat_test %>%
      select(- c(initial_number_sheep, initial_number_wolves,
                 sheep_gain_from_food, wolves_gain_from_food,
                 sheep_reproduce, wolves_reproduce,
                 grass_regrowth)) %>%
      as.matrix
    
    # train the multivariate random forest
    # predict test data
    pred <- build_forest_predict(trainX = X, trainY = Y,
                                 n_tree = 20, m_feature = 1,
                                 min_leaf = 5, testX = testX)
    
    pred_initial_sheep <- pred[, 1]
    pred_initial_wolves <- pred[, 2]
    pred_food_sheep <- pred[, 3]
    pred_food_wolves <- pred[, 4]
    pred_rep_sheep <- pred[, 5]
    pred_rep_wolves <- pred[, 6]
    pred_grass <- pred[, 7]
  
    # compute mean input parameters in training data for
    # point prediction computation
    mean_initial_sheep <- mean(dat$initial_number_sheep)
    mean_initial_wolves <- mean(dat$initial_number_wolves)
    mean_food_sheep <- mean(dat$sheep_gain_from_food)
    mean_food_wolves <- mean(dat$wolves_gain_from_food)
    mean_rep_sheep <- mean(dat$sheep_reproduce)
    mean_rep_wolves <- mean(dat$wolves_reproduce)
    mean_grass <- mean(dat$grass_regrowth)
  
    # add error computations
    results_df <- results_df %>%
      add_row(ComputeErrorsContinuous(pred_initial_sheep,
                                      dat_test$initial_number_sheep,
                                      mean_initial_sheep,
                                      variable = 'initial number of sheep',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_initial_wolves,
                                      dat_test$initial_number_wolves,
                                      mean_initial_sheep,
                                      variable = 'initial number of wolves',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_food_sheep,
                                      dat_test$sheep_gain_from_food,
                                      mean_food_sheep,
                                      variable = 'sheep gain from food',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_food_wolves,
                                      dat_test$wolves_gain_from_food,
                                      mean_food_wolves,
                                      variable = 'wolves gain from food',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_rep_sheep,
                                      dat_test$sheep_reproduce,
                                      mean_rep_sheep,
                                      variable = 'probability sheep reproduce',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_rep_wolves,
                                      dat_test$wolves_reproduce,
                                      mean_rep_wolves,
                                      variable = 'probability wolves reproduce',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_grass,
                                      dat_test$grass_regrowth,
                                      mean_grass,
                                      variable = 'grass regrowth time',
                                      fold = i))
  }
  
  # compute mean of each statistic over the 5 folds
  results_df <- results_df %>%
    group_by(variable)%>%
    summarise_all(mean) %>%
    select(- fold) %>%
    add_column(sampling_method = sampling_method,
               timesteps = timesteps,
               noise = noise)
  
  return(results_df)
}
```

For now:
```{r}
out <- WolfSheepRandomForest(ws_train,
                             sampling_method = 'random',
                             timesteps = 'all',
                             noise = 'no')
```

1) no noise, 10 steps, random sampling

2) no noise, 20 steps, random sampling

3) no noise, 50 steps, random sampling

4) no noise, endpoint, random sampling

4) no noise, 10 steps, lhs

5) no noise, 20 steps, lhs

6) no noise, 50 steps, lhs

7) no noise, endpoing, 

1) no noise, 10 steps, random sampling

2) no noise, 20 steps, random sampling

3) no noise, 50 steps, random sampling

4) no noise, 10 steps, lhs

5) no noise, 20 steps, lhs

6) no noise, 50 steps, random sampling

# Visualise results
Compare each error metric:
```{r}
out_long <- out %>%
  pivot_longer(cols = c(perc_correct_cat,
                        perc_correct,
                        RMSE, NRMSE, point_pred),
               names_to = 'metric',
               values_to = 'vals')

# no noise
out_long %>%
  filter(noise == 'no') %>%
  ggplot(mapping = aes(x = timesteps,
                       y = vals,
                       fill = sampling_method)) +
  geom_bar(position = 'dodge', stat = 'identity') +
  facet_wrap(~ metric + variable,
             scales = 'free_y')

# with noise
out_long %>%
  filter(noise == 'yes') %>%
  ggplot(mapping = aes(x = timesteps,
                       y = vals,
                       fill = sampling_method)) +
  geom_bar(position = 'dodge', stat = 'identity') +
  facet_grid(~ metric + variable,
             scales = 'free_y')
```
