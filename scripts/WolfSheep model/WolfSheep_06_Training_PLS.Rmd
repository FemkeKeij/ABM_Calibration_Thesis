---
title: "WolfSheep_06_Training_PLS"
author: "Femke Keij S2647168"
date: "2023-07-12"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear working directory & set random seed:
```{r}
rm(list = ls(all = TRUE))

set.seed(42)
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for ggplot
library(directlabels)
library(patchwork)
library(ggbeeswarm)

# for creating the cross-validation folds
library(caret)

# for partial least squares
library(pls)
```

Functions used:
```{r}
source('scripts/WolfSheep/WolfSheep_Functions.R')
```

Read in the data:
```{r}
# training data
ws_train <- read_csv('data/processed/wolfsheep_timesteps_training.csv')
```

# Fitting with cross-validation
Function to cross-validate partial least squares:
```{r}
WolfSheepSimpleRegression <- function(data,
                                      sampling_method,
                                      timesteps,
                                      noise){
  # create the folds
  flds <- createFolds(1:nrow(data),
                      k = 5, list = TRUE, returnTrain = FALSE)

  # to store the results
  results_df <- tibble(fold = numeric(),
                       variable = character(),
                       perc_correct = numeric(),
                       perc_correct_cat = numeric(),
                       RMSE = numeric(),
                       NRMSE = numeric(),
                       point_pred = numeric())

  # for each cross-validation fold
  for(i in 1:5){
    # remove the test fold to create the training data
    dat <- data %>%
      filter(!combination_number %in% unlist(flds[i])) %>%
      select(- combination_number)
  
    # obtain the test fold
    dat_test <- data %>%
      filter(combination_number %in% unlist(flds[i])) %>%
      select(- combination_number)
  
    # train the partial linear regressions
    fit <- plsr(cbind(initial_number_sheep, initial_number_wolves, 
                  sheep_gain_from_food, wolves_gain_from_food,
                  sheep_reproduce, wolves_reproduce,
                  grass_regrowth) ~ ., data = dat,
                validation = 'LOO', scale = TRUE)
    
    # cross-validation to determine number of components
    # ncomp.cv <- crossval(fit)$ncomp
    ncomp.cv = 3
    
    # predict test data using fitted PLS
    pred <- predict(fit, newdata = dat_test, ncomp = ncomp.cv)
    pred_initial_sheep <- pred[, 1, 1]
    pred_initial_wolves <- pred[, 2, 1]
    pred_food_sheep <- pred[, 3, 1]
    pred_food_wolves <- pred[, 4, 1]
    pred_rep_sheep <- pred[, 5, 1]
    pred_rep_wolves <- pred[, 6, 1]
    pred_grass <- pred[, 7, 1]
  
    # compute mean input parameters in training data for
    # point prediction computation
    mean_initial_sheep <- mean(dat$initial_number_sheep)
    mean_initial_wolves <- mean(dat$initial_number_wolves)
    mean_food_sheep <- mean(dat$sheep_gain_from_food)
    mean_food_wolves <- mean(dat$wolves_gain_from_food)
    mean_rep_sheep <- mean(dat$sheep_reproduce)
    mean_rep_wolves <- mean(dat$wolves_reproduce)
    mean_grass <- mean(dat$grass_regrowth)
  
    # add error computations
    results_df <- results_df %>%
      add_row(ComputeErrorsContinuous(pred_initial_sheep,
                                      dat_test$initial_number_sheep,
                                      mean_initial_sheep,
                                      variable = 'initial number of sheep',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_initial_wolves,
                                      dat_test$initial_number_wolves,
                                      mean_initial_sheep,
                                      variable = 'initial number of wolves',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_food_sheep,
                                      dat_test$sheep_gain_from_food,
                                      mean_food_sheep,
                                      variable = 'sheep gain from food',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_food_wolves,
                                      dat_test$wolves_gain_from_food,
                                      mean_food_wolves,
                                      variable = 'wolves gain from food',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_rep_sheep,
                                      dat_test$sheep_reproduce,
                                      mean_rep_sheep,
                                      variable = 'probability sheep reproduce',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_rep_wolves,
                                      dat_test$wolves_reproduce,
                                      mean_rep_wolves,
                                      variable = 'probability wolves reproduce',
                                      fold = i)) %>%
      add_row(ComputeErrorsContinuous(pred_grass,
                                      dat_test$grass_regrowth,
                                      mean_grass,
                                      variable = 'grass regrowth time',
                                      fold = i))
  }
  
  # compute mean of each statistic over the 5 folds
  results_df <- results_df %>%
    group_by(variable)%>%
    summarise_all(mean) %>%
    select(- fold) %>%
    add_column(sampling_method = sampling_method,
               timesteps = timesteps,
               noise = noise)
  
  return(results_df)
}
```

For now:
```{r}
out <- WolfSheepSimpleRegression(ws_train,
                                 sampling_method = 'random',
                                 timesteps = 'all',
                                 noise = 'no')
```

1) no noise, 10 steps, random sampling

2) no noise, 20 steps, random sampling

3) no noise, 50 steps, random sampling

4) no noise, endpoint, random sampling

4) no noise, 10 steps, lhs

5) no noise, 20 steps, lhs

6) no noise, 50 steps, lhs

7) no noise, endpoing, 

1) no noise, 10 steps, random sampling

2) no noise, 20 steps, random sampling

3) no noise, 50 steps, random sampling

4) no noise, 10 steps, lhs

5) no noise, 20 steps, lhs

6) no noise, 50 steps, random sampling

# Visualise results
Compare each error metric:
```{r}
VisualiseErrorMetrics(out = out,
                      noise = FALSE)

VisualiseErrorMetrics(out = out,
                      noise = TRUE)
```