---
title: "Reading in NetLogo output files"
author: "Femke Keij S2647168"
date: '2022-07-14'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
Clear working directory & set random seed:
```{r}
rm(list = ls(all = TRUE))

set.seed(42)
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for Latin hypercube sampling
library(lhs)

# for ggplot
library(directlabels)
library(patchwork)
```

Read in the data:
```{r}
# complete output data
fire_output <- read_csv('data/raw/fire_output.csv')

# training data
fire_train <- read_csv(
  'data/processed/fire_train.csv')
fire_train$directions <- as.factor(fire_train$directions)

# test data
fire_test <- read_csv(
  'data/processed/fire_test.csv')
fire_test$directions <- as.factor(fire_test$directions)
```

# Setting up the samples
Random samples:
5, 10, 20, 30, 40, 50, 60, 70, and 80 $%$ of the total parameter space.
```{r}
N <- nrow(fire_output)
# range of (training) sample sizes to work with
n <- c(0.05 * N, 0.1 * N, 0.2 * N, 0.3 * N, 0.4 * N, 0.5 * N,
       0.6 * N, 0.7 * N, nrow(fire_train))
```

Set up the Latin hypercube sample(s).
```{r}
# Function for Latin hypercube sampling using the ranges of each of the variables
LatinHypercubeSampling <- function(n, k = 2){
  # n: number of samples to draw
  # k: number of variables over which to sample
  
  # LHS with n samples over k variables
  A <- randomLHS(n = n, k = k)
  
  # transform samples to represent the parameter space
  # create empty matrix to hold parameter space samples
  B <- matrix(nrow = nrow(A), ncol = ncol(A))
  # round uniform distribution between 1 and 99 for
  # tree density
  B[,1] <- round(qunif(A[,1], min = 1, max = 99), digits = 0)
  # binomial distribution for '4 vs. 8 directions'
  B[,2] <- qbinom(p = A[,2], size = 1, prob = 0.5)
  B[, 2] <- B[, 2] * 4 + 4
  
  return(B)
}

# create an empty list to hold each of the LHSs
samples <- list()
# loop through the sample sizes and obtain LHS for each
for(i in 1:length(n)){
  samples[[i]] <- LatinHypercubeSampling(n = n[i], k = 4)
}
```

Now I take a random instance of the the training data for each of the LHS samples obtained above.
```{r}
for(i in 1:9){
  for(j in 1:n[i]){
    # take a density and direction from the sample
    density <- samples[[i]][j, 1]
    direction <- samples[[i]][j, 2]
    # find an instance in the training data with those
    # values
    ind_true <- which(fire_train$density == density & 
                   fire_train$directions == direction)
    # sample 1 instance in case there are multiple that match
    ind_use <- sample(ind_true, size = 1)
    # retrieve burn_percentage and ticks
    burn_perc <- fire_train$burn_percentage[ind_use]
    ticks <- fire_train$ticks[ind_use]
    samples[[i]][j, 3] <- burn_perc
    samples[[i]][j, 4] <- ticks
  }
}
```

# Functions
```{r}
LatinHypercubeSampleFitting <- function(ticks = FALSE){
  # create tibble to store results
  length_tib <- sum(nrow(fire_test) * length(n))
  lhs_results <- tibble(direction_true = numeric(length_tib),
                        direction_pred = numeric(length_tib),
                        density_true = numeric(length_tib),
                        density_pred = numeric(length_tib),
                        burn_true = numeric(length_tib),
                        burn_pred = numeric(length_tib),
                        n = numeric(length_tib),
                        ticks_included = numeric(length_tib))
  
  # set count variable for filling out the tibble
  count <- 1
  
  # for each of the different sample sizes, estimate
  # each case of the test data
  
  for(j in 1:9){
    for(k in 1:nrow(fire_test)){
      if(ticks == FALSE){
        # take an instance of the test data
        burn_match <- fire_test$burn_percentage[k]
        # see which instance of the LHS has the smallest
        # distance to the test data
        diffs <- sqrt((samples[[j]][,3] - burn_match)^2)
        ind <- which(diffs == min(diffs))
        lhs_results$ticks_included[count] <- 'no'
      } else{
        # take a burn percentage and number of ticks
        burn_match <- fire_test$burn_percentage[k]
        ticks_match <- fire_test$ticks[k]
        # see which instance of the LHS has the smallest
        # distance to that burn percentage and number of ticks
        # weigh by inverse of variance
        diffs_burn <- (1 / var(samples[[j]][,3]))*
          (samples[[j]][,3] - burn_match)^2
        diffs_ticks <- (1 / var(samples[[j]][,4]))*
          (samples[[j]][,4] - ticks_match)^2
        # to weight them similarly to the burn percentages
        diffs <- sqrt(diffs_burn + diffs_ticks)
        ind <- which(diffs == min(diffs))
        lhs_results$ticks_included[count] <- 'yes'
      }
      
      # in case there are multiple instances that match
      # equally well, select 1 randomly
      if(length(ind) != 1){
        ind <- sample(ind, size = 1)
      }
      # retrieve the density and direction that generated
      # the minimum difference & store all info in the tibble
      lhs_results$direction_true[count] <-
        as.numeric(fire_test$directions[k])
      lhs_results$direction_pred[count] <- samples[[j]][ind, 2]
      lhs_results$density_true[count] <- fire_test$density[k]
      lhs_results$density_pred[count] <- samples[[j]][ind, 1]
      lhs_results$burn_true[count] <-
        fire_test$burn_percentage[k]
      lhs_results$burn_pred[count] <- samples[[j]][ind, 3]
      lhs_results$n[count] <- n[j]
      count <- count + 1
    }
  }

# correct format of direction_true variable
lhs_results %>%
  mutate(direction_true = replace(direction_true, direction_true == 1, 4),
         direction_true = replace(direction_true, direction_true == 2, 8)) -> lhs_results
  
# return results
return(lhs_results)
}
```

The following function summarises the following:
- % of cases in which both direction and density are estimated correctly
- % of cases in which density is estimated correctly
- % of cases in which direction is estimated correctly
- % of cases in which the density is estimated to be within 10% of the true density
- RMSE of the estimated density
- NRMSE of the estimated density
- point prediction performance of the estimated density
```{r}
LatinHypercubeErrors <- function(lhs_results,
                                 ticks = FALSE){
  
  # means of the density parameter in each of the training
  # data sets (required for point prediction performance)
  means <- numeric(9)
  for(i in 1:9){
    means[i] <- mean(samples[[i]][,1])
  }

  merge(lhs_results, as_tibble(cbind(n, means)),
        by = c('n')) %>%
    group_by(n) %>%
    summarise(perc_correct = sum(direction_true ==
                                   direction_pred &
                                   density_true == density_pred)
                / nrow(fire_test),
              perc_density_correct = sum(density_true ==
                                         density_pred) /
                nrow(fire_test),
              perc_direction_correct = sum(direction_true ==
                                           direction_pred) /
                nrow(fire_test),
              perc_correct_cat = sum(density_pred >=
                                       density_true - 5 &
                                       density_pred <=
                                       density_true + 5) /
                nrow(fire_test),
              RMSE_density = sqrt(sum((density_pred - density_true)^2))
                /nrow(fire_test),
              NRMSE_density = (sqrt(sum((density_pred -
                                   density_true)^2))
                     / nrow(fire_test)) / sd(density_true),
              point_pred_performance = 1 - 
                sum(sqrt((density_pred - density_true)^2)) /
                sum(sqrt((density_true - means)^2)),
              RMSE_burn = sqrt(sum((burn_pred - burn_true)^2))
                /nrow(fire_test),
              NRMSE_burn = (sqrt(sum((burn_pred -
                                   burn_true)^2))
                     / nrow(fire_test)) / sd(burn_true)) ->
    lhs_errors
  
  lhs_errors$ticks_included <- 
    if(ticks == TRUE){'yes'} else{'no'}

  return(lhs_errors)
}
```

# Running functions
Without ticks
```{r}
lhs_results_noticks <- 
  LatinHypercubeSampleFitting(ticks = FALSE)
```

```{r}
lhs_errors_noticks <- LatinHypercubeErrors(lhs_results_noticks,
                                           ticks = FALSE)
```

With ticks
```{r}
lhs_results_ticks <- LatinHypercubeSampleFitting(ticks = TRUE)
``` 

```{r}
lhs_errors_ticks <- LatinHypercubeErrors(lhs_results_ticks,
                                         ticks = TRUE)
```

Merge results
```{r}
lhs_results <- rbind(lhs_results_noticks, lhs_results_ticks)
``` 

```{r}
lhs_errors <- rbind(lhs_errors_noticks, lhs_errors_ticks)
```

# Plots
Predicted vs. true density (largest sample size only):
```{r}
PlotPredTrueDensity <- function(results, n){
  # results: data frame with fitting results
  # n: sample size for which to plot
  supp_labs <- c('without ticks', 'with ticks')
  names(supp_labs) <- c('no', 'yes')
  
  results %>%
    filter(n == n) %>%
    ggplot(mapping = aes(x = density_pred,
                         y = density_true,
                         colour = direction_correct)) +
    facet_grid(. ~ ticks_included,
               labeller = labeller(ticks_included = supp_labs)) +
    geom_point() +
    theme_minimal() +
    labs(x = 'predicted density',
         y = 'true density',
         colour = 'Number of directions \n predicted correctly') +
    theme(panel.grid.minor.y = element_blank(),
          panel.grid.minor.x = element_blank()) -> plot
  
  return(plot)
}
```


```{r}
lhs_results$n <- as.factor(lhs_results$n)
lhs_results$direction_true <-
  as.factor(lhs_results$direction_true)
lhs_results$direction_pred <-
  as.factor(lhs_results$direction_pred)
lhs_results %>%
  mutate(direction_correct = (direction_pred == direction_true)) -> lhs_results

PlotPredTrueDensity(lhs_results, n = 1584)

ggsave('figures/fire_LHS_pred_vs_true.pdf')
```

% of predictions that are correct
```{r}
PlotPercCorrect <- function(errors, n_plot){
  # errors: data frame with calculated error measures
  # n_plot: sample sizes to plot (can be multiple)
  errors %>%
    filter(n %in% n_plot)%>%
    ggplot(mapping = aes(x = n, y = perc_correct,
                         fill = ticks_included)) +
    geom_bar(stat = 'identity',
             position = position_dodge()) +
    labs(y = 'density & direction',
         x = 'training sample size',
         fill = 'Ticks included') +
    theme_minimal() +
    theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) -> p1
  
  errors %>%
    filter(n %in% n_plot) %>%
    ggplot(mapping = aes(x = n, y = perc_density_correct,
                         fill = ticks_included)) +
    geom_bar(stat = 'identity',
             position = position_dodge()) +
    labs(y = 'density',
         x = 'training sample size',
         fill = 'Ticks included') +
    theme_minimal() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()) -> p2
  
  errors %>%
    filter(n %in% n_plot) %>%
    ggplot(mapping = aes(x = n, y = perc_direction_correct,
                         fill = ticks_included)) +
    geom_bar(stat = 'identity',
             position = position_dodge()) +
    labs(y = 'direction',
         x = 'training sample size',
         fill = 'Ticks included') +
    theme_minimal() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()) -> p3
  
  errors %>%
    filter(n %in% n_plot) %>%
    ggplot(mapping = aes(x = n, y = perc_correct_cat,
                         fill = ticks_included)) +
    geom_bar(stat = 'identity',
             position = position_dodge()) +
    labs(y = 'density within \n 10% of true density',
         x = 'training sample size',
         fill = 'Ticks included') +
    theme_minimal() +
    theme(panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()) -> p4

  plot <- p1 + p2 + p3 + p4 +
    plot_layout(guides = 'collect') +
    plot_annotation(tag_levels = 'A',
                    title = '% correctly predicted') & 
    theme(plot.tag = element_text(size = 8))
  
  return(plot)
}
```

```{r}
PlotPercCorrect(lhs_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_LHS_perc_correct.pdf')
```

RMSE, NRMSE & point prediction performance
```{r}
lhs_errors %>%
  ggplot(mapping = aes(x = n, y = RMSE_density,
                       fill = ticks_included)) +
  geom_bar(stat = 'identity',
           position = position_dodge()) +
  labs(fill = 'Ticks included') +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) -> p1

lhs_errors %>%
  ggplot(mapping = aes(x = n, y = NRMSE_density,
                       fill = ticks_included)) +
  geom_bar(stat = 'identity',
           position = position_dodge()) +
  labs(fill = 'Ticks included') +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) -> p2

lhs_errors %>%
  ggplot(mapping = aes(x = n, y = point_pred_performance,
                       fill = ticks_included)) +
  geom_bar(stat = 'identity',
           position = position_dodge()) +
  labs(fill = 'Ticks included',
       y = 'point prediction performance') +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) -> p3

p1 + p2 + p3 +
  plot_layout(guides = 'collect') +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 8))

ggsave('figures/fire_LHS_RMSE.pdf')
```

RMSE for burn percentage:
```{r}
lhs_errors %>%
  ggplot(mapping = aes(x = n, y = RMSE_burn,
                       fill = ticks_included)) +
  geom_bar(stat = 'identity',
           position = position_dodge()) +
  labs(fill = 'Ticks included') +
  theme_minimal() +
  theme(panel.grid.major.x = element_blank(),
        panel.grid.minor.x = element_blank()) +
  labs(x = 'Training sample size',
       y = 'RMSE burn percentage')
```