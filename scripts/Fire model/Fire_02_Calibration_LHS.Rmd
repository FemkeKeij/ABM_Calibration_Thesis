---
title: "Reading in NetLogo output files"
author: "Femke Keij S2647168"
date: '2022-07-14'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
Clear working directory & set random seed:
```{r}
rm(list = ls(all = TRUE))

set.seed(42)
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for Latin hypercube sampling
library(lhs)

# for ggplot
library(directlabels)
library(patchwork)
```

Source files for error calcuation and plotting functions:
```{r}
source('scripts/Fire model/Fire_ErrorFunctions.R')
```

Read in the data:
```{r}
# complete output data
fire_output <- read_csv('data/raw/fire_output.csv')

# training data
fire_train <- read_csv(
  'data/processed/fire_train.csv')
fire_train$directions <- as.factor(fire_train$directions)

# test data
fire_test <- read_csv(
  'data/processed/fire_test.csv')
fire_test$directions <- as.factor(fire_test$directions)
```

# Setting up the samples
Random samples:
5, 10, 20, 30, 40, 50, 60, 70, and 80 $%$ of the total parameter space.
```{r}
N <- nrow(fire_output)
# range of (training) sample sizes to work with
n <- c(0.05 * N, 0.1 * N, 0.2 * N, 0.3 * N, 0.4 * N, 0.5 * N,
       0.6 * N, 0.7 * N, nrow(fire_train))
```

Set up the Latin hypercube sample(s).
```{r}
# Function for Latin hypercube sampling using the ranges of each of the variables
LatinHypercubeSampling <- function(n, k = 2){
  # n: number of samples to draw
  # k: number of variables over which to sample
  
  # LHS with n samples over k variables
  A <- randomLHS(n = n, k = k)
  
  # transform samples to represent the parameter space
  # create empty matrix to hold parameter space samples
  B <- matrix(nrow = nrow(A), ncol = ncol(A))
  # round uniform distribution between 1 and 99 for
  # tree density
  B[,1] <- round(qunif(A[,1], min = 1, max = 99), digits = 0)
  # binomial distribution for '4 vs. 8 directions'
  B[,2] <- qbinom(p = A[,2], size = 1, prob = 0.5)
  B[, 2] <- B[, 2] * 4 + 4
  
  return(B)
}

# create an empty list to hold each of the LHSs
samples <- list()
# loop through the sample sizes and obtain LHS for each
for(i in 1:length(n)){
  samples[[i]] <- LatinHypercubeSampling(n = n[i], k = 4)
}
```

Now I take a random instance of the the training data for each of the LHS samples obtained above.
```{r}
for(i in 1:9){
  for(j in 1:n[i]){
    # take a density and direction from the sample
    density <- samples[[i]][j, 1]
    direction <- samples[[i]][j, 2]
    # find an instance in the training data with those
    # values
    ind_true <- which(fire_train$density == density & 
                   fire_train$directions == direction)
    # sample 1 instance in case there are multiple that match
    ind_use <- sample(ind_true, size = 1)
    # retrieve burn_percentage and ticks
    burn_perc <- fire_train$burn_percentage[ind_use]
    ticks <- fire_train$ticks[ind_use]
    samples[[i]][j, 3] <- burn_perc
    samples[[i]][j, 4] <- ticks
  }
}
```

# Functions
```{r}
LatinHypercubeSampleFitting <- function(ticks = FALSE){
  # create tibble to store results
  length_tib <- sum(nrow(fire_test) * length(n))
  lhs_results <- tibble(direction_true = numeric(length_tib),
                        direction_pred = numeric(length_tib),
                        density_true = numeric(length_tib),
                        density_pred = numeric(length_tib),
                        burn_true = numeric(length_tib),
                        burn_pred = numeric(length_tib),
                        n = numeric(length_tib),
                        ticks_included = numeric(length_tib))
  
  # set count variable for filling out the tibble
  count <- 1
  
  # for each of the different sample sizes, estimate
  # each case of the test data
  
  for(j in 1:9){
    for(k in 1:nrow(fire_test)){
      if(ticks == FALSE){
        # take an instance of the test data
        burn_match <- fire_test$burn_percentage[k]
        # see which instance of the LHS has the smallest
        # distance to the test data
        diffs <- sqrt((samples[[j]][,3] - burn_match)^2)
        ind <- which(diffs == min(diffs))
        lhs_results$ticks_included[count] <- 'no'
      } else{
        # take a burn percentage and number of ticks
        burn_match <- fire_test$burn_percentage[k]
        ticks_match <- fire_test$ticks[k]
        # see which instance of the LHS has the smallest
        # distance to that burn percentage and number of ticks
        # weigh by inverse of variance
        diffs_burn <- (1 / var(samples[[j]][,3]))*
          (samples[[j]][,3] - burn_match)^2
        diffs_ticks <- (1 / var(samples[[j]][,4]))*
          (samples[[j]][,4] - ticks_match)^2
        # to weight them similarly to the burn percentages
        diffs <- sqrt(diffs_burn + diffs_ticks)
        ind <- which(diffs == min(diffs))
        lhs_results$ticks_included[count] <- 'yes'
      }
      
      # in case there are multiple instances that match
      # equally well, select 1 randomly
      if(length(ind) != 1){
        ind <- sample(ind, size = 1)
      }
      # retrieve the density and direction that generated
      # the minimum difference & store all info in the tibble
      lhs_results$direction_true[count] <-
        as.numeric(fire_test$directions[k])
      lhs_results$direction_pred[count] <- samples[[j]][ind, 2]
      lhs_results$density_true[count] <- fire_test$density[k]
      lhs_results$density_pred[count] <- samples[[j]][ind, 1]
      lhs_results$burn_true[count] <-
        fire_test$burn_percentage[k]
      lhs_results$burn_pred[count] <- samples[[j]][ind, 3]
      lhs_results$n[count] <- n[j]
      count <- count + 1
    }
  }

# correct format of direction_true variable
lhs_results %>%
  mutate(direction_true = replace(direction_true, direction_true == 1, 4),
         direction_true = replace(direction_true, direction_true == 2, 8)) -> lhs_results
  
# return results
return(lhs_results)
}
```

# Running functions
Without ticks
```{r}
lhs_results_noticks <- 
  LatinHypercubeSampleFitting(ticks = FALSE)
```

```{r}
# means of density in each of the training samples
means <- numeric(9)
  for(i in 1:9){
    means[i] <- mean(samples[[i]][,1])
  }

lhs_errors_noticks <- ComputeErrors(lhs_results_noticks,
                                    ticks = FALSE,
                                    means,
                                    pred_int_included = FALSE)
```

With ticks
```{r}
lhs_results_ticks <- LatinHypercubeSampleFitting(ticks = TRUE)
``` 

```{r}
lhs_errors_ticks <- ComputeErrors(lhs_results_ticks,
                                    ticks = TRUE,
                                    means,
                                    pred_int_included = FALSE)
```

Merge results
```{r}
lhs_results <- rbind(lhs_results_noticks, lhs_results_ticks)
``` 

```{r}
lhs_errors <- rbind(lhs_errors_noticks, lhs_errors_ticks)
```

# Plots
Fix results and errors data frames:
```{r}
lhs_results <- lhs_results %>%
  mutate(n = factor(n),
         direction_true = factor(direction_true),
         direction_pred = factor(direction_pred),
         direction_correct = (direction_pred == direction_true))

lhs_errors <- lhs_errors %>%
  mutate(n = factor(n))
```

Predicted vs. true density (largest sample size only):
```{r}
PlotPredTrueDensity(lhs_results, n = 1584)

ggsave('figures/fire_LHS_predtrue_density.pdf')
```
Predicted vs. true burn percentage (largest sample size only):
```{r}
PlotPredTrueBurn(lhs_results, n = 1584)

ggsave('figures/fire_LHS_predtrue_burn')
```
% correctly predicted parameters (density & directions):
```{r}
PlotPercCorrectParams(lhs_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_LHS_perc_correct.pdf')
```
RMSE, NRMSE and point prediction performance for density parameter:
```{r}
PlotRMSEParams(lhs_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_LHS_RMSE_density.pdf')
```
RMSE for burn percentage:
```{r}
PlotRMSEOut(lhs_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_LHS_RMSE_burn.pdf')
```