---
title: "Fire_02_Explore_Model"
author: "Femke Keij S2647168"
date: '2022-07-21'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Clear working directory:
```{r}
rm(list = ls(all = TRUE)) 
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for arranging ggplots
library(patchwork)

# for ggplot aesthetics
library(directlabels)
library(RColorBrewer)

# for k-means clustering
library(factoextra)

# for hierarchical dynamic time warping clustering
library(dtwclust)

# for computing trends in data
library(trend)
```

Random seed:
```{r}
set.seed(42)
```

Read in the data:
```{r}
# complete data set
fire_output <- read_csv(
  'data/processed/fire_full.csv')

# output data summary
fire_summary <- read_csv(
  'data/processed/fire_summary.csv')
# rename 'mean_burn_percentage' to 'burn_percentage'
fire_summary <- fire_summary %>%
  rename(burn_percentage = mean_burn_percentage)
```

# Visualising parameter space
Plot time series:
```{r}
p1 <- fire_summary %>%
  ggplot(mapping = aes(x = ticks, y = burn_percentage,
                       group = combination_number)) +
  geom_line(alpha = 0.2) +
  labs(y = 'percentage trees burned') +
  theme_minimal() +
  theme(panel.grid.minor = element_blank()) +
  facet_grid(~ directions,
             labeller = 'label_both')
```

Plot burn percentage at last tick as a function of density at start of simulation and number of directions:
```{r}
p2 <- fire_summary %>%
  group_by(combination_number) %>%
  filter(ticks == max(ticks)) %>%
  ggplot(mapping = (aes(x = density, y = burn_percentage,
                        group = as.factor(directions),
                        colour = as.factor(directions)))) +
  labs(x = 'tree density (%)',
       y = '% of burned trees at last tick',
       colour = 'number of directions') +
  geom_path (linewidth = 1) +
  theme_minimal()
```

Plot number of ticks against density:
```{r}
p3 <- fire_output %>%
  group_by(combination_number) %>%
  filter(ticks == max(ticks)) %>%
  ggplot(mapping = aes(x = density, y = ticks, 
                       colour = as.factor(directions))) +
  geom_point(alpha = 0.5) +
  labs(x = 'tree density (%)',
       y = 'number of ticks until fire extinguishes',
       colour = 'number of directions') +
  theme_minimal()
```

Plot both:
```{r}
p1 / (p2 + p3) +
  plot_layout(guides = 'collect')

ggsave('figures/fire_parameterspace.pdf')
```

# Identifying equifinality
The parameter space plots show equifinality, especially around the lowest and highest tree densities.

Apply a k-means clustering to the burn percentages at the middle and final timestep. Then see which parameter combinations end up in the same cluster.
Start by formatting the data for the analysis
```{r}
kmeans_data <- fire_summary %>%
  filter(time_label %in% c('middle', 'end')) %>%
  select(combination_number, burn_percentage, time_label) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage) %>%
  select(middle, end) %>%
  scale() 
```

Determine optimal number of clusters:
- elbow method: we want to minimize the total within-cluster variation (or within-cluster sum of squares). we compute the wss for a number of different clusters, and then choose the number of clusters where we see the 'elbow' occur
- average silhouette method: this approach inspects how well each observation fits within its cluster. If the average is high, that indicates good clustering.
```{r}
# elbow method
fviz_nbclust(kmeans_data, kmeans, method = "wss")

# silhouette method
fviz_nbclust(kmeans_data, kmeans, method = "silhouette")
```
The optimal number of clusters is 2.

K-means clustering with 2 centers:
```{r}
clustering <- kmeans(kmeans_data, centers = 2, nstart = 25)

fviz_cluster(clustering, data = kmeans_data) +
  labs(title = element_blank()) +
  theme_minimal() +
  theme(legend.position = 'none',
        panel.grid.minor = element_blank())
```

Now inspect which parameter combinations ended up in the same cluster.
```{r}
clustered_parameters <- fire_summary %>%
  select(combination_number,
         directions, density) %>%
  distinct() %>%
  add_column(cluster = clustering$cluster)


p1 <- clustered_parameters %>%
  ggplot(mapping = aes(x = as.factor(cluster),
                       y = density,
                       colour = as.factor(cluster),
                       fill = as.factor(cluster))) +
           geom_jitter(width = 0.2) +
           geom_boxplot(alpha = 0.1, width = 0.4,
                        outlier.colour = 'transparent') +
           theme_minimal() +
           labs(x = '2-means clusters',
                y = 'tree density (%)') +
           theme(legend.position = 'none')

p2 <- clustered_parameters %>%
  ggplot(mapping = aes(x = as.factor(cluster),
                       y = directions,
                       colour = as.factor(cluster),
                       fill = as.factor(cluster))) +
           geom_jitter(width = 0.2) +
           geom_boxplot(alpha = 0.1, width = 0.4,
                        outlier.colour = 'transparent') +
           theme_minimal() +
           labs(x = '2-means clusters',
                y = ' number of directions') +
           theme(legend.position = 'none')

p1 + p2
```
The clusters show that we can distinguish fairly well between high and low tree densities based on the burn percentage during the simulation. However, it is difficult to distinguish between the directions. Therefore, we can conclude that there is equifinality for the number of directions.

Hierarchical dynamic time warping clustering
```{r}
# create data with all time points, standardize
hierarchical_data <- fire_summary %>%
  select(combination_number,
         burn_percentage, ticks) %>%
  pivot_wider(names_from = ticks,
              values_from = burn_percentage) %>%
  select(- combination_number) %>%
  scale()

# change to list format to allow for different lengths of time series
#   as input for the hierarchical clustering DTW algorithm
hierarchical_data_list <- list()

for(i in 1:nrow(hierarchical_data)){
  # keep only ticks with values
  throw <- which(is.na(hierarchical_data[i, ]))
  keep <- hierarchical_data[i, - throw]
  hierarchical_data_list <- append(hierarchical_data_list, keep)
}

# train hierarchical clustering with DTW
hierarchical_clust <- tsclust(hierarchical_data_list,
                              type = 'h',
                              k = 2L,
                              distance = 'dtw')

# plot results
plot(hierarchical_clust, type = 'sc')

# plot rest of results (haven't tried running this yet)
hierarchical_clustered_parameters <- fire_summary %>%
  select(combination_number,
         directions, density) %>%
  distinct() %>%
  add_column(cluster = cutree(hierarchical_clust, k = 2L))

p1 <- hierarchical_clustered_parameters %>%
  ggplot(mapping = aes(x = as.factor(cluster),
                       y = density,
                       colour = as.factor(cluster),
                       fill = as.factor(cluster))) +
           geom_jitter(width = 0.2) +
           geom_boxplot(alpha = 0.1, width = 0.4,
                        outlier.colour = 'transparent') +
           theme_minimal() +
           labs(x = 'clusters',
                y = 'tree density (%)') +
           theme(legend.position = 'none')

p2 <- hierarchical_clustered_parameters %>%
  ggplot(mapping = aes(x = as.factor(cluster),
                       y = directions,
                       colour = as.factor(cluster),
                       fill = as.factor(cluster))) +
           geom_jitter(width = 0.2) +
           geom_boxplot(alpha = 0.1, width = 0.4,
                        outlier.colour = 'transparent') +
           theme_minimal() +
           labs(x = 'clusters',
                y = ' number of directions') +
           theme(legend.position = 'none')

p1 + p2
```
Here I choose the number of clusters based on trial and error. 

# Identifying unidentifiable parameters
Correlation between parameters and outputs:
```{r}
p1 <- fire_summary %>%
  filter(time_label %in% c('middle', 'end')) %>%
  ggplot(mapping = aes(x = density, y = burn_percentage)) +
  geom_point() +
  geom_smooth(method = 'lm', se = FALSE) +
  theme_minimal() +
  labs(x = 'tree density', y = 'percentage of burned trees') +
  facet_grid(directions ~ time_label,
             labeller = 'label_both')

p2 <- fire_summary %>%
  filter(time_label %in% c('middle', 'end')) %>%
  ggplot(mapping = aes(x = as.factor(directions), y = burn_percentage)) +
  geom_boxplot() +
  theme_minimal() +
  labs(x = 'number of directions', y = 'percentage of burned trees') +
  facet_grid(~ time_label)

p1 / p2
```
2 issues to look at:
1) flat slopes / no influence on output
We see that the density slopes are not flat, so not issue 1. We also see that the boxplots for 4 and 8 are different, so not issue 1.
2) similar slopes / influences
We see that the slopes for density go up with increasing tree density and we also see that the mean in the boxplot goes up when moving from 4 to 8 directions. So we may have issue 2 here.

# Temporal autocorrelation plots
Compute (partial) autocorrelation for each time series
```{r}
# dataframe to store results
autocorrelation_df <- tibble(combination_number = numeric(),
                             lag = numeric(),
                             acf = numeric(),
                             pacf = numeric())

# per time series (parameter set)
for(i in unique(fire_summary$combination_number)){
  select <- fire_summary %>%
    filter(combination_number == i)
  
  # compute acf and pacf
  acf <- acf(select$burn_percentage, plot = FALSE,
             lag.max = 20, type = 'correlation')$acf
  pacf <- pacf(select$burn_percentage, plot = FALSE,
               lag.max = 20)$acf
  
  # add 0 in front of the pacf series, since they start at lag 1, not 0
  add_df <- tibble(combination_number = rep(i, length(acf)),
                   lag = 1:length(acf),
                   acf = acf,
                   pacf = c(0, pacf))
  
  autocorrelation_df <- autocorrelation_df %>%
    add_row(add_df)
}
```

Plot (partial) autocorrelations:
```{r}
acf_plot <- autocorrelation_df %>%
  mutate_at(vars(acf, pacf), ~ replace(., is.nan(.), 0)) %>%
  ggplot(mapping = aes(x = lag, y = acf,
                       colour = as.factor(combination_number))) +
  geom_line() +
  labs(y = 'autocorrelation burn percentage') +
  theme_minimal() +
  theme(legend.position = 'none')

pacf_plot <- autocorrelation_df %>%
  mutate_at(vars(acf, pacf), ~ replace(., is.nan(.), 0)) %>%
  ggplot(mapping = aes(x = lag, y = pacf,
                       colour = as.factor(combination_number))) +
  geom_line() +
  labs(y = 'partial autocorrelation burn percentage') +
  theme_minimal() +
  theme(legend.position = 'none')

autocorrelation_plot <- acf_plot / pacf_plot

ggsave(autocorrelation_plot,
       filename = 'figures/fire_autocorrelation.pdf')
```

# Summary statistics
Some stats for the Fire model:
```{r}
summary(fire_output)
```

Check that the training and test data are similarly distributed:
```{r}
summary(fire_test)
```

```{r}
summary(fire_train)
```

The medians for the burn percentages are different.
```{r}
par(mfrow = c(1,3))
hist(fire_output$burn_percentage)
hist(fire_test$burn_percentage)
hist(fire_train$burn_percentage)
```
