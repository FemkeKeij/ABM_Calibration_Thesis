---
title: "Fire_00_Run_Model"
author: "Femke Keij S2647168"
date: "2023-02-06"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import Python modules:
```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('white')
sns.set_context('talk')

import pyNetLogo # to run NetLogo from RStudio
```

Import R packages:
```{r}
# for importing / working with tidy data
library(tidyverse)
```

# Running all possible parameter combinations
Link to and start the Fire model:
```{python}
netlogo = pyNetLogo.NetLogoLink(gui = True) # start netlogo

netlogo.load_model(r"C:\Users\Femke Keij\OneDrive\Thesis\R projects\LU thesis local\models\Fire_myversion.nlogo")
# open model
```

To determine how often the model should be run, I look at the coefficient of variation: $standard deviation / mean * 100$. At the number of repetitions where this remains approximately the same, we can assume convergence [LU40]. This is only true for linear relationships, which we don't have here, but it will give an indication of how often to run the model:
```{python}
runs = [5, 10, 20, 30]
densities = [5, 10, 25, 50, 75, 100]
directions = [4, 8]
CVs = pd.DataFrame(columns = ['runs', 'CV'])

for k in runs:
  for i in directions:
    # set number of directions
    direction = str(i)
    netlogo.command(''.join(['set directions ', direction]))
    for j in densities:
      # set density
      density = str(j)
      netlogo.command(''.join(['set density ', density]))
      # set up data frame to store results
      perc_burn_df = pd.DataFrame(columns = ['perc_burn'])
      for x in range(1, k):
        # set up
        netlogo.command('setup')
        # execute for 10,000 ticks or until the model is done
        netlogo.command('repeat 10000 [go]')
        # record number of burned trees and number of initial trees
        initial = netlogo.report('initial-trees')
        burned = netlogo.report('burned-trees')
        # calculate % burned
        perc_burn = burned / initial * 100
        # store
        perc_burn_df = perc_burn_df.append({'perc_burn': perc_burn}, ignore_index = True)
      
  # calculate CV
  CV_new = perc_burn_df.mean() / perc_burn_df.std() * 100
  CVs = CVs.append({'runs': runs[k]}, {'CV' : CV_new)
```

Set up the model and run 10 times for each density, record the percentage of trees burned:
```{python}
densities = list(range(1,100))
directions = [4, 8]
parameter_space_df = pd.DataFrame(columns = ['density', 'burn_percentage', 'directions', 'ticks'])

for y in directions:
  direction = str(y)
  netlogo.command(''.join(['set directions ', direction]))
  for d in densities:
    # density
    density = str(d)
    # set density
    netlogo.command(''.join(['set density ', density]))
    # set a random seed
    netlogo.command('clean')
    # repeat the execution of the model 10 times to account
    # for stochasticity
    for x in range(1,11):
      # set up
      netlogo.command('setup')
      # execute for 10,000 ticks or until the model is done
      netlogo.command('repeat 10000 [go]')
      # record number of burned trees and number of initial trees
      initial = netlogo.report('initial-trees')
      burned = netlogo.report('burned-trees')
      # record number of ticks after last trees are
      # burned out
      ticks = netlogo.report('ticks')
      # calculate % burned
      perc_burn = burned / initial * 100
      # store in data frame
      parameter_space_df = parameter_space_df.append({'density': d,'burn_percentage': perc_burn, 'directions': y, 'ticks': ticks}, ignore_index = True)
```

Save data as a csv file.
```{python}
parameter_space_df.to_csv("C:/Users/Femke Keij/OneDrive/Thesis/R projects/LU thesis local/data/raw/fire_output.csv")
```

Close the model:
```{python}
netlogo.kill_workspace()
```

Stop running the python environment:
```{python}
quit
```

# Split into training and test data
Clear working directory:
```{r}
rm(list = ls(all = TRUE)) 
```

Import csv output format for the fire model as tidy data. We ignore the first column because it contains the indices.
```{r}
fire_output <- read_csv("data/raw/fire_output.csv",
                        col_names = TRUE,
                        col_select = 2:4)
```

Manipulate data so that there is 1 outcome for each density:
The outcomes for each density are summarised by their mean burn percentage, and the minimum and maximum burn percentage
```{r}
# group the data by tree density
fire_output %>%
  group_by(density, directions) %>%
# take the mean burn % over the 10 runs for each density
# register the minimum and maximum burn % for each density
  summarise(burned = mean(burn_percentage), 
            max = max(burn_percentage),
            min = min(burn_percentage),
            .groups = 'keep') ->
# assign to new data frame
  fire_summary

fire_summary %>%
  write_csv(file = 'data/processed/fire_summary.csv')
```

Set up the training and test data:
I'm using a 80 - 20 split.
```{r}
set.seed(42)

ind <- sample(1:nrow(fire_output),
              size = nrow(fire_output) * 0.2,
              replace = FALSE)

fire_output %>%
  slice(ind) %>%
  write_csv(file = 'data/processed/fire_test.csv')

fire_output %>%
  slice(-ind) %>%
  write_csv(file = 'data/processed/fire_train.csv')
```