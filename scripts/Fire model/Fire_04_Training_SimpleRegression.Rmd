---
title: "Fire_03_Calibration_SimpleRegression"
author: "Femke Keij S2647168"
date: "2023-02-14"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminaries
Clear working directory & set random seed:
```{r}
rm(list = ls(all = TRUE))

set.seed(42)
```

Packages used:
```{r}
# for importing / working with tidy data
library(tidyverse)

# for creating cross-validation folds
library(caret)

# for error computation
library(mltools)

# for ggplot
library(directlabels)
library(patchwork)
library(ggbeeswarm)
```

Source files for error computation and plotting functions:
```{r}
source('scripts/Fire model/Fire_Functions.R')
```

Read in the data:
```{r}
# training data
fire_training <- read_csv('data/training/fire_training.csv')
```

# Fitting
Fit a linear regression to predict density and a logistic regression to predict directions. We use 5-fold cross-validation to assess predictive performance.

There are multiple versions here:
- full time series, 10 timesteps, 20 timesteps, endpoints only (I'm leaving out the 50 timesteps here since the simulations are mostly too short for that)
- runs summarised or not
- data without noise, data with output noise, data with output and temporal noise
There are no variations with different sample sizes or sampling methods here, since I sampled the full parameter space for this model.

To perform:
1) select relevant sample size, sampling method, summarisation of runs, noise, and type of datapoints
2) select relevant data columns, include combination_number, ticks, outputs, and input parameters
3) pivot wider to make each time step a column
4) feed to fitting function

```{r}
FireSimpleRegressionFitting <- function(data_clean, data_noise){
  # data_clean: the data frame containing the input parameters as well as the relevant outputs
  # data_noise: if testing should be done on noisy data, supply data with noise here
  
  noise <- ifelse(any(is.na(data_noise)), FALSE, TRUE)
  
  # create the folds
  flds <- createFolds(1:nrow(data_clean),
                      k = 5, list = TRUE, returnTrain = FALSE)

  # to store the results
  results_df <- tibble(density = numeric(),
                       directions = numeric(),
                       density_pred = numeric(),
                       directions_pred = numeric(),
                       fold = numeric())
  
  # set directions 4 to 0 and 8 to 1 (eases interpretation of logistic regression)
  data_clean <- data_clean %>%
    mutate(directions = ifelse(directions == 4, 0, 1))
  if(noise){
    data_noise <- data_noise %>%
      mutate(directions = ifelse(directions == 4, 0, 1))
  }
  
  # for each cross-validation fold
  for(i in 1:5){
    # remove the test fold to create the training data
    dat_train <- data_clean %>%
      filter(!row_number() %in% unlist(flds[i]))
    
    # obtain the test fold
    if(noise){
      dat_test <- data_noise %>%
        filter(row_number() %in% unlist(flds[i]))
    } else {
      dat_test <- data_clean %>%
        filter(row_number() %in% unlist(flds[i]))
    }
  
    # train the linear & logistic regressions
    fit_lm_density <- lm(formula = density ~ . - directions,
                         data = dat_train)
    fit_glm_directions <- glm(formula = directions ~ . - density,
                              data = dat_train)
    
    # predict the density & directions in the left-out fold
    predict_density <- predict.lm(fit_lm_density,
                                  newdata = dat_test,
                                  interval = 'prediction')
    predict_directions <- predict.glm(fit_glm_directions,
                                      newdata = dat_test,
                                      type = 'response')
    # correct predictions for directions to 4 vs. 8
    for(j in 1:length(predict_directions)){
      predict_directions[j] <- ifelse(predict_directions[j] <= 0.5,
                                      4, 8)
    }
    
    # add the predictions to the data frame
    results_new <- tibble(density = dat_test$density,
                          directions = dat_test$directions,
                          density_pred = predict_density[, 1],
                          directions_pred = predict_directions,
                          fold = i)
    results_df <- results_df %>%
      add_row(results_new)
  }
  # correct back to 4 and 8 directions
  results_df <- results_df %>%
    mutate(directions = ifelse(directions == 0, 4, 8))
  
  return(results_df)
}
```

Compute the errors:
```{r}
FireComputeErrors <- function(predictions,
                              sample_size, sample_method,
                              summarise_runs, noise, datapoints){
  # predictions: dataframe with results from fitting
  # requires the columns density, density_pred,
  # directions, directions_pred
  
  # sample_size, sample_method, summarise_runs, noie, datapoints: experiment info to be added to output data row
  
  # to store results
  errors <- tibble(perc_correct_params = numeric(),
                   perc_density_correct = numeric(),
                   perc_directions_correct = numeric(),
                   perc_correct_cat_density = numeric(),
                   RMSE_density = numeric(),
                   NRMSE_density = numeric(),
                   point_pred_performance_density = numeric(),
                   directions_kappa = numeric(),
                   directions_f1 = numeric(),
                   directions_mcc = numeric(),
                   fold = numeric())
  
  # for each fold
  for(i in 1:5){
    # retrieve correct rows
    dat <- predictions %>%
      filter(fold == i)
    
    # compute mean density in training data
    mean_density <- predictions %>%
      filter(fold != i) %>%
      summarise(mean(density))
    
    # compute errors
    errors_new <- dat %>%
      # % correctly predicted direction + density in test set
      summarise(perc_correct_params = sum(
        directions == directions_pred &
          density == round(density_pred)) / nrow(dat) * 100,
      # % correctly predicted density in test set
      perc_density_correct = sum(density == round(density_pred)) /
                nrow(dat) * 100,
      # % correctly predicted direction in test set
      perc_directions_correct = sum(directions == directions_pred) /
                nrow(dat) * 100,
      # % predicted density within 10% of true density in test set
      perc_correct_cat_density = sum(density_pred >= density - 5 &
                                       density_pred <= density + 5) /
                                        nrow(dat) * 100,
      # RMSE of predicted vs. true density
      RMSE_density = sqrt(sum((density_pred - density)^2))
              / nrow(dat),
      # NRMSE of predicted vs. true density
      NRMSE_density = (sqrt(sum((density_pred - density)^2))
                               / nrow(dat)) / sd(density),
      # point prediction performance for density
      point_pred_performance_density = 1 - 
                sum(sqrt((density_pred - density)^2)) /
                sum(sqrt((density - mean_density)^2)))
  
    # add columns for the metrics for directions
    errors_new$directions_kappa <- NA
    errors_new$directions_f1 <- NA
    errors_new$directions_mcc <- NA
  
    # add the error measures for the directions
    # compute confusion matrix
    cm <- confusionMatrix(as.factor(predictions$directions_pred),
                          as.factor(predictions$directions),
                          mode = 'everything')
    # retrieve kappa, F1, and MCC
    errors_new$directions_kappa = cm$overall[2]
    errors_new$directions_f1 = cm$byClass[7]
    errors_new$directions_mcc = mcc(as.factor(predictions$directions_pred),
                                as.factor(predictions$directions))
    
    # add fold & add to errors data frame
    errors_new$fold <- i
    errors <- errors %>%
      add_row(errors_new)
  }
  
  # compute the mean statistics for each fold
  errors <- errors %>%
    summarise_all(mean) %>%
    select(- fold) %>%
    # add the experiment info to the df
    add_column(sample_size = sample_size,
               sample_method = sample_method,
               summarise_runs = summarise_runs,
               noise = noise,
               datapoints = datapoints)
  
  # return data row
  return(errors)
}
```

Function to fill out data so that each simulation has the same length of time series: (the final simulation value is copied to all other timesteps after)
```{r}
FillOutData <- function(data){
  # check if any are missing the first time step (can happen in the noise case)
  if(any(is.na(data[, 7]))){
    # add value from second timepoint
    for(j in 1:nrow(data)){
      if(is.na(data[j, 7])){
        data[j, 7] <- data[j, 8]
      }
    }
  }
  
  # for each burn_percentage timestep column
  for(i in 7:ncol(data)){
    # go through each row
    for(j in 1:nrow(data)){
      # if the value is NA (because simulation stopped earlier)
      if(is.na(data[j, i])){
        # copy value from previous column
        data[j, i] <- data[j, i - 1]
      }
    }
  }
  return(data)
}
```

Run for each combination:
- endpoints only, time steps version here: endpoint, middle point, total number of ticks, mean, min, max, sd, trend
- runs summarised or not
- data without noise, data with output noise, data with output and temporal noise

time steps, not summarised
```{r}
# time steps, not summarised, data without noise
data_time_full_clean <- fire_training %>%
  filter(datapoints == 'timesteps',
         summarise_runs == 'full') %>%
  select(time_label, density, directions, burn_percentage, total_ticks,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage)

fit_data_time_full_clean <-
  FireSimpleRegressionFitting(data_time_full_clean,
                              data_noise = NA)
errors_data_time_full_clean <- 
  FireComputeErrors(fit_data_time_full_clean,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'full',
                    noise = 'clean',
                    datapoints = 'timepoints')

# dataframe to store all errors
errors <- errors_data_time_full_clean

# time steps, not summarised, data with output noise
data_time_full_outputnoise <- fire_training %>%
  filter(datapoints == 'timesteps',
         summarise_runs == 'full') %>%
  select(time_label, density, directions, burn_percentage_noise,
         total_ticks, mean_burn, min_burn, max_burn, sd_burn,
         trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage_noise)

fit_data_time_full_outputnoise <- 
  FireSimpleRegressionFitting(data_time_full_clean,
                              data_noise = data_time_full_outputnoise)

errors_data_time_full_outputnoise <- 
  FireComputeErrors(fit_data_time_full_outputnoise,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'full',
                    noise = 'output noise',
                    datapoints = 'timepoints')

errors <- errors %>%
  add_row(errors_data_time_full_outputnoise)
```

time steps, summarised
```{r}
# time steps, summarised, data without noise
data_time_sum_clean <- fire_training %>%
  filter(datapoints == 'timesteps',
         summarise_runs == 'summarised') %>%
  select(time_label, density, directions, burn_percentage, total_ticks,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage)

fit_data_time_sum_clean <-
  FireSimpleRegressionFitting(data_time_sum_clean,
                              data_noise = NA)
errors_data_time_sum_clean <- 
  FireComputeErrors(fit_data_time_sum_clean,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'summarised',
                    noise = 'clean',
                    datapoints = 'timepoints')

errors <- errors %>%
  add_row(errors_data_time_sum_clean)

# time steps, summarised, data with output noise
data_time_sum_outputnoise <- fire_training %>%
  filter(datapoints == 'timesteps',
         summarise_runs == 'summarised') %>%
  select(time_label, density, directions, burn_percentage_noise,
         total_ticks, mean_burn, min_burn, max_burn, sd_burn,
         trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage_noise)

fit_data_time_sum_outputnoise <- 
  FireSimpleRegressionFitting(data_time_sum_clean,
                              data_noise = data_time_sum_outputnoise)

errors_data_time_sum_outputnoise <- 
  FireComputeErrors(fit_data_time_sum_outputnoise,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'summarised',
                    noise = 'output noise',
                    datapoints = 'timepoints')

errors <- errors %>%
  add_row(errors_data_time_sum_outputnoise)
```

endpoints, not summarised
```{r}
# endpoints, not summarised, data without noise
data_end_full_clean <- fire_training %>%
  filter(datapoints == 'endpoints',
         summarise_runs == 'full') %>%
  select(time_label, density, directions, burn_percentage,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage)

fit_data_end_full_clean <-
  FireSimpleRegressionFitting(data_end_full_clean,
                              data_noise = NA)
errors_data_end_full_clean <- 
  FireComputeErrors(fit_data_end_full_clean,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'full',
                    noise = 'clean',
                    datapoints = 'endpoints')

errors <- errors %>%
  add_row(errors_data_end_full_clean)

# endpoints, not summarised, data with output noise
data_end_full_outputnoise <- fire_training %>%
  filter(datapoints == 'endpoints',
         summarise_runs == 'full') %>%
  select(time_label, density, directions, burn_percentage_noise,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage_noise)

fit_data_end_full_outputnoise <-
  FireSimpleRegressionFitting(data_end_full_clean,
                              data_end_full_outputnoise)
errors_data_end_full_outputnoise <- 
  FireComputeErrors(fit_data_end_full_outputnoise,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'full',
                    noise = 'output noise',
                    datapoints = 'endpoints')

errors <- errors %>%
  add_row(errors_data_end_full_outputnoise)
```

endpoints, summarised
```{r}
# endpoints, summarised, data without noise
data_end_sum_clean <- fire_training %>%
  filter(datapoints == 'endpoints',
         summarise_runs == 'summarised') %>%
  select(time_label, density, directions, burn_percentage,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage)

fit_data_end_sum_clean <-
  FireSimpleRegressionFitting(data_end_sum_clean,
                              data_noise = NA)
errors_data_end_sum_clean <- 
  FireComputeErrors(fit_data_end_sum_clean,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'summarised',
                    noise = 'clean',
                    datapoints = 'endpoints')

errors <- errors %>%
  add_row(errors_data_end_sum_clean)

# endpoints, summarised, data with output noise
data_end_sum_outputnoise <- fire_training %>%
  filter(datapoints == 'endpoints',
         summarise_runs == 'summarised') %>%
  select(time_label, density, directions, burn_percentage_noise,
         mean_burn, min_burn, max_burn, sd_burn, trend_burn) %>%
  pivot_wider(names_from = time_label,
              values_from = burn_percentage_noise)

fit_data_end_sum_outputnoise <-
  FireSimpleRegressionFitting(data_end_sum_clean,
                              data_end_sum_outputnoise)
errors_data_end_sum_outputnoise <- 
  FireComputeErrors(fit_data_end_sum_outputnoise,
                    sample_size = 198,
                    sample_method = 'full',
                    summarise_runs = 'summarised',
                    noise = 'output noise',
                    datapoints = 'endpoints')

errors <- errors %>%
  add_row(errors_data_end_sum_outputnoise)
```

# Plots

## Errors
Fix results and errors data frames:
```{r}
regression_results <- regression_results %>%
  mutate(n = factor(n),
         direction_true = factor(direction_true),
         direction_pred = factor(direction_pred),
         direction_correct = (direction_pred == direction_true))

regression_errors <- regression_errors %>%
  mutate(n = factor(n))
```
### Predicted vs. true
Predicted vs. true for density, directions, and burn percentage
```{r}
p1 <- PlotPredTrueDensity(regression_results, n = 1584)
p2 <- PlotPredTrueDirection(regression_results, n = 1584)
p3 <- PlotPredTrueBurn(regression_results, n = 1584)

p1 / p2 / p3
```
Predicted vs. true density (largest sample size only):
```{r}
PlotPredTrueDensity(regression_results, n = 1584)

ggsave('figures/fire_regression_predtrue_density.pdf')
```
Confusion matrix for predicted vs. true directions:
```{r}
PlotPredTrueDirection(regression_results, n = 1584)

ggsave('figures/fire_regression_predtrue_direction.pdf')
```
Predicted vs. true burn percentage (largest sample size only):
```{r}
PlotPredTrueBurn(regression_results, n = 1584)

ggsave('figures/fire_regression_predtrue_burn.pdf')
```
### Parameters
% correctly predicted parameters (density & directions):
```{r}
PlotPercCorrectParams(regression_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_regression_perc_correct.pdf')
```
RMSE, NRMSE, point prediction performance, and coverage for density parameter:
```{r}
PlotErrorsDensity(regression_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_regression_density_metrics.pdf')
```
F1, kappa score, and MCC for directions:
```{r}
PlotErrorsDirections(regression_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_regression_directions_metrics.pdf')
```
### Outcome variable
RMSE for burn percentage:
```{r}
PlotRMSEOut(regression_errors, n_plot = c(99, 792, 1584))

ggsave('figures/fire_regression_RMSE_burn.pdf')
```

## Model fit
Fitted regression lines (smallest and largest sample size):
Linear regression for density
```{r}
RegressionLinePlot <- function(sample = 1, ticks = TRUE){
  if(ticks){
    formula <- 'density ~ burn_percentage + directions + ticks'
    subtitle <- 'with ticks'
  } else{
    formula <- 'density ~ burn_percentage + directions'
    subtitle <- 'without ticks'
  }
  
  subtitle <- paste(subtitle, ' sample size ', n[sample])
  
  ind_sample <- sample(1:nrow(fire_train), size = n[sample])
  fire_train_sub <- fire_train[ind_sample, ]
  
  fire_train_sub %>%
    ggplot(mapping = aes(x = burn_percentage, y = density,
                         colour = directions)) +
    geom_point() +
    geom_line(data = fortify(lm(data = fire_train_sub,
                                formula = formula)),
              aes(x = burn_percentage, y = .fitted)) +
    labs(x = '% burned trees at last tick',
         y = 'tree density (%)',
         subtitle = subtitle) +
    theme_minimal() +
    coord_flip() -> returnplot

  return(returnplot)
}

p1 <- RegressionLinePlot(sample = 1, ticks = TRUE)
p2 <- RegressionLinePlot(sample = 1, ticks = FALSE)
p3 <- RegressionLinePlot(sample = 9, ticks = TRUE)
p4 <- RegressionLinePlot(sample = 9, ticks = FALSE)

p1 + p2 + p3 + p4 +
  plot_layout(guides = 'collect') +
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 8))

ggsave('figures/fire_regression_fit.pdf')
```

Logistic regression for directions (only largest training sample size)
```{r}
fit_glm_ticks <- glm(data = fire_train,
               formula = 'directions ~ burn_percentage + density + ticks',
               family = binomial(link = 'logit'))
plot_df_ticks <- augment(fit_glm_ticks, type.predict = 'response')

p1 <- plot_df_ticks %>%
  ggplot(mapping = aes(x = density, y = .fitted,
                       colour = directions)) +
  geom_point(size = 0.5) +
  labs(x = 'tree density',
       y = 'probability number of directions is 8',
       colour = 'true number \n of directions') +
  geom_hline(yintercept = 0.5,
             linetype = 'dashed',
             colour = 'darkgreen') +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = 'lightgrey', fill = NA)) +
  annotate(geom = 'text',
           x = 17, y = 0.25,
           label = 'directions \n classified \n as 4',
           size = 3) +
  annotate(geom = 'text',
           x = 83, y = 0.75,
           label = 'directions \n classified \n as 8',
           size = 3) +
  ylim(c(0, 1)) +
  ggtitle('ticks')

fit_glm_noticks <- glm(data = fire_train,
               formula = 'directions ~ burn_percentage + density',
               family = binomial(link = 'logit'))
plot_df_noticks <- augment(fit_glm_noticks, type.predict = 'response')

p2 <- plot_df_noticks %>%
  ggplot(mapping = aes(x = density, y = .fitted,
                       colour = directions)) +
  geom_point(size = 0.5) +
  labs(x = 'tree density',
       y = 'probability number of directions is 8',
       colour = 'true number \n of directions') +
  geom_hline(yintercept = 0.5,
             linetype = 'dashed',
             colour = 'darkgreen') +
  theme_minimal() +
  theme(panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = 'lightgrey', fill = NA)) +
  annotate(geom = 'text',
           x = 17, y = 0.25,
           label = 'directions \n classified \n as 4',
           size = 3) +
  annotate(geom = 'text',
           x = 83, y = 0.75,
           label = 'directions \n classified \n as 8',
           size = 3) +
  ylim(c(0, 1)) +
  ggtitle('no ticks')

patch <- p1 + p2 +
    plot_layout(guides = 'collect') +
    plot_annotation(tag_levels = 'A') & 
    theme(plot.tag = element_text(size = 8)) &
    xlab(NULL)
  
wrap_elements(panel = patch) +
  labs(tag = 'tree density (%)') +
  theme(plot.tag = element_text(size = rel(1)),
        plot.tag.position = 'bottom')

ggsave('figures/fire_logistic_fit.pdf')
```